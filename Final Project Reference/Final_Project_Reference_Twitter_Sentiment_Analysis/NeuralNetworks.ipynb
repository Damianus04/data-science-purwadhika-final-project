{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python38564bitnlpcondaef908e0ce2224ddc9b8f7d79349b98f4",
   "display_name": "Python 3.8.5 64-bit ('nlp': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "INFO:tensorflow:tokens_length=568 inputs_length=512 targets_length=114 noise_density=0.15 mean_noise_span_length=3.0 \n"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy\n",
    "import random\n",
    "import time\n",
    "from datetime import timedelta\n",
    "\n",
    "import trax\n",
    "from trax import fastmath\n",
    "from trax import layers as tl\n",
    "from trax.supervised import training\n",
    "\n",
    "import EngineFiles.TweetFormat as tf\n",
    "\n",
    "from EngineFiles.DeepLearning import NeuralNetworkDataPrepro as NND\n",
    "from EngineFiles.DeepLearning import NeuralNetworkObject as NNO\n",
    "from EngineFiles.DeepLearning import NeuralNetworkModel as NNM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('Data/indonesia_Tweet/clean_tweets.csv')\n",
    "df.dropna(subset=['Tweet'],inplace=True)\n",
    "alay_lang = tf.bahasa_slang()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('EngineFiles/Word2Vec/idwiki_clean.txt', 'r', encoding='utf-8') as f:\n",
    "    idwiki = f.read()\n",
    "\n",
    "idwiki = idwiki.split('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SPLIT TRAIN TEST SET\n",
    "df_train, df_test, x_train, x_train_pos, x_train_neg, x_test, x_test_pos, x_test_neg, y_train, y_test, index_train, index_test = NND.splitDataset(df, 0.2, 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "                Tweet\nlabel    type        \nnegative test    1527\n         train   6106\npositive test    1312\n         train   5248",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th></th>\n      <th>Tweet</th>\n    </tr>\n    <tr>\n      <th>label</th>\n      <th>type</th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th rowspan=\"2\" valign=\"top\">negative</th>\n      <th>test</th>\n      <td>1527</td>\n    </tr>\n    <tr>\n      <th>train</th>\n      <td>6106</td>\n    </tr>\n    <tr>\n      <th rowspan=\"2\" valign=\"top\">positive</th>\n      <th>test</th>\n      <td>1312</td>\n    </tr>\n    <tr>\n      <th>train</th>\n      <td>5248</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "source": [
    "df_test = df.copy()\n",
    "df_test['type'] = ['not_set'] * df_test.shape[0]\n",
    "df_test.loc[index_train, 'type'] = 'train'\n",
    "df_test.loc[index_test, 'type'] = 'test'\n",
    "df_test.groupby(['label', 'type']).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Total words in vocab : 1388642\n"
    }
   ],
   "source": [
    "# BUILD VOCABULARY\n",
    "vocab = NND.createVocab(x_train, idwiki)\n",
    "print(f'Total words in vocab : {len(vocab)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Actual tweet : tanggal pas pilih kepala daerah pilih ah\nTensor of tweet : [1070, 267, 25, 26, 27, 25, 1028]\n"
    }
   ],
   "source": [
    "# CONVERT TWEETS TO TENSORS (TEST FUNCTION)\n",
    "print(f'Actual tweet : {x_test_pos[0]}')\n",
    "print('Tensor of tweet :', NND.tweet2tensor(x_test_pos[0], vocabulary=vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "inputs shape : (4, 21)\ntargets shape : (4,)\nexample weights shape : (4,)\n\ninput tensor : [ 3  4  5  6  7  8  9 10 11 12 13 14 14 15 16 12 17 18 18 17 19], target 1, exm_weights 1\ninput tensor : [20 21 22 23  4 20 24 25 26 27 28 29 30 31 32 33 34 35 36 37  0], target 1, exm_weights 1\ninput tensor : [38 39 40  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0], target 0, exm_weights 1\ninput tensor : [65 66 67  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0], target 0, exm_weights 1\n"
    }
   ],
   "source": [
    "# CREATE BATCH GENERATOR & DATA GENERATOR (TEST FUNCTION)\n",
    "random.seed(30)\n",
    "tmp = NND.train_generator(x_train_pos, x_train_neg, vocab, batch_size=4)\n",
    "tmp_inputs, tmp_targets, tmp_exm_weights = next(tmp)\n",
    "\n",
    "print(f'inputs shape : {tmp_inputs.shape}')\n",
    "print(f'targets shape : {tmp_targets.shape}')\n",
    "print(f'example weights shape : {tmp_exm_weights.shape}')\n",
    "print()\n",
    "\n",
    "for i, t in enumerate(tmp_inputs):\n",
    "    print(f'input tensor : {t}, target {tmp_targets[i]}, exm_weights {tmp_exm_weights[i]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Testing data : [[-2. -1.  0.]\n [ 0.  1.  2.]]\nOutput of ReLU : [[0. 0. 0.]\n [0. 1. 2.]]\n"
    }
   ],
   "source": [
    "# TEST RELU CLASS\n",
    "x = numpy.array([[-2.0, -1.0, 0.0], [0.0, 1.0, 2.0]], dtype=float)\n",
    "relu_layer = NNO.ReLU()\n",
    "print(f'Testing data : {x}')\n",
    "print('Output of ReLU :', relu_layer(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Weights : [[-0.02837108  0.09368162 -0.10050076  0.14165013  0.10543301  0.09108126\n  -0.04265672  0.0986188  -0.05575325  0.00153249]\n [-0.20785688  0.0554837   0.09142365  0.05744595  0.07227863  0.01210617\n  -0.03237354  0.16234995  0.02450038 -0.13809784]\n [-0.06111237  0.01403724  0.08410042 -0.1094358  -0.10775021 -0.11396459\n  -0.05933381 -0.01557652 -0.03832145 -0.11144515]]\nForward output : [[-3.0395496   0.9266802   2.5414743  -2.050473   -1.9769388  -2.582209\n  -1.7952735   0.94427425 -0.8980402  -3.7497487 ]]\n"
    }
   ],
   "source": [
    "# TEST DENSE CLASS\n",
    "dense_layer = NNO.Dense(n_units=10)\n",
    "random_key = fastmath.random.get_prng(seed=0)\n",
    "z = fastmath.numpy.array([[2.0, 7.0, 25.0]])\n",
    "\n",
    "dense_layer.init(z, random_key)\n",
    "print('Weights :', dense_layer.weights)\n",
    "print('Forward output :', dense_layer(z))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "<class 'trax.layers.combinators.Serial'>\n"
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "Serial[\n  Embedding_1388642_256\n  Mean\n  Dense_2\n  LogSoftmax\n]"
     },
     "metadata": {}
    }
   ],
   "source": [
    "# TEST MODEL\n",
    "tmp = NNM.classifier(vocab_size=len(vocab))\n",
    "print(type(tmp))\n",
    "display(tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "/Users/blackdisk/Project/Purwadhika_Final_Project/EngineFiles/DeepLearning/model/\n"
    }
   ],
   "source": [
    "# CREATE OUTPUT DIRECTORY FOR THE MODEL\n",
    "output_dir = '~/Project/Purwadhika_Final_Project/EngineFiles/DeepLearning/model/'\n",
    "output_dir_expand = os.path.expanduser(output_dir)\n",
    "print(output_dir_expand)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TRAIN THE MODEL\n",
    "batch_size = 16\n",
    "random.seed(271)\n",
    "\n",
    "train_task = training.TrainTask(labeled_data = NND.train_generator(x_train_pos, x_train_neg, vocab, batch_size, True),\n",
    "                                loss_layer = tl.CrossEntropyLoss(),\n",
    "                                optimizer = trax.optimizers.Adam(0.01),\n",
    "                                n_steps_per_checkpoint = 10\n",
    "                                )\n",
    "\n",
    "eval_task = training.EvalTask(labeled_data = NND.val_generator(x_test_pos, x_test_neg, vocab, batch_size, True),\n",
    "                                metrics = [tl.CrossEntropyLoss(), tl.Accuracy()]\n",
    "                            )\n",
    "\n",
    "model = NNM.classifier(vocab_size=len(vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "\nStep      1: Ran 1 train steps in 83.89 secs\nStep      1: train CrossEntropyLoss |  0.69781309\nStep      1: eval  CrossEntropyLoss |  0.75031227\nStep      1: eval          Accuracy |  0.43750000\n\nStep     10: Ran 9 train steps in 153.14 secs\nStep     10: train CrossEntropyLoss |  0.72035336\nStep     10: eval  CrossEntropyLoss |  0.79513711\nStep     10: eval          Accuracy |  0.43750000\n\nStep     20: Ran 10 train steps in 159.24 secs\nStep     20: train CrossEntropyLoss |  0.69483221\nStep     20: eval  CrossEntropyLoss |  0.67076182\nStep     20: eval          Accuracy |  0.56250000\n\nStep     30: Ran 10 train steps in 146.35 secs\nStep     30: train CrossEntropyLoss |  0.66534519\nStep     30: eval  CrossEntropyLoss |  0.55639279\nStep     30: eval          Accuracy |  0.81250000\n\nStep     40: Ran 10 train steps in 144.52 secs\nStep     40: train CrossEntropyLoss |  0.63103765\nStep     40: eval  CrossEntropyLoss |  0.58525956\nStep     40: eval          Accuracy |  0.62500000\n\nStep     50: Ran 10 train steps in 161.41 secs\nStep     50: train CrossEntropyLoss |  0.62199098\nStep     50: eval  CrossEntropyLoss |  0.49944550\nStep     50: eval          Accuracy |  0.75000000\n\nStep     60: Ran 10 train steps in 153.69 secs\nStep     60: train CrossEntropyLoss |  0.53499240\nStep     60: eval  CrossEntropyLoss |  0.47853765\nStep     60: eval          Accuracy |  0.87500000\n\nStep     70: Ran 10 train steps in 160.44 secs\nStep     70: train CrossEntropyLoss |  0.54538667\nStep     70: eval  CrossEntropyLoss |  0.56104571\nStep     70: eval          Accuracy |  0.68750000\n\nStep     80: Ran 10 train steps in 149.76 secs\nStep     80: train CrossEntropyLoss |  0.50966018\nStep     80: eval  CrossEntropyLoss |  0.39794564\nStep     80: eval          Accuracy |  0.81250000\n\nStep     90: Ran 10 train steps in 153.05 secs\nStep     90: train CrossEntropyLoss |  0.51925963\nStep     90: eval  CrossEntropyLoss |  0.44685802\nStep     90: eval          Accuracy |  0.75000000\n\nStep    100: Ran 10 train steps in 145.91 secs\nStep    100: train CrossEntropyLoss |  0.59672475\nStep    100: eval  CrossEntropyLoss |  0.96193182\nStep    100: eval          Accuracy |  0.56250000\n\nStep    110: Ran 10 train steps in 148.93 secs\nStep    110: train CrossEntropyLoss |  0.52880275\nStep    110: eval  CrossEntropyLoss |  0.39527535\nStep    110: eval          Accuracy |  0.87500000\n\nStep    120: Ran 10 train steps in 139.77 secs\nStep    120: train CrossEntropyLoss |  0.51966405\nStep    120: eval  CrossEntropyLoss |  0.41341960\nStep    120: eval          Accuracy |  0.87500000\n\nStep    130: Ran 10 train steps in 143.12 secs\nStep    130: train CrossEntropyLoss |  0.49090663\nStep    130: eval  CrossEntropyLoss |  0.64867151\nStep    130: eval          Accuracy |  0.75000000\n\nStep    140: Ran 10 train steps in 143.96 secs\nStep    140: train CrossEntropyLoss |  0.46237159\nStep    140: eval  CrossEntropyLoss |  0.37423146\nStep    140: eval          Accuracy |  0.87500000\n\nStep    150: Ran 10 train steps in 144.06 secs\nStep    150: train CrossEntropyLoss |  0.42453259\nStep    150: eval  CrossEntropyLoss |  0.51822758\nStep    150: eval          Accuracy |  0.75000000\n\nStep    160: Ran 10 train steps in 146.09 secs\nStep    160: train CrossEntropyLoss |  0.44452667\nStep    160: eval  CrossEntropyLoss |  0.32368660\nStep    160: eval          Accuracy |  0.87500000\n\nStep    170: Ran 10 train steps in 162.38 secs\nStep    170: train CrossEntropyLoss |  0.44594902\nStep    170: eval  CrossEntropyLoss |  0.64689237\nStep    170: eval          Accuracy |  0.68750000\n\nStep    180: Ran 10 train steps in 148.80 secs\nStep    180: train CrossEntropyLoss |  0.58840281\nStep    180: eval  CrossEntropyLoss |  0.45547217\nStep    180: eval          Accuracy |  0.81250000\n\nStep    190: Ran 10 train steps in 160.43 secs\nStep    190: train CrossEntropyLoss |  0.48255187\nStep    190: eval  CrossEntropyLoss |  0.31215104\nStep    190: eval          Accuracy |  0.87500000\n\nStep    200: Ran 10 train steps in 153.53 secs\nStep    200: train CrossEntropyLoss |  0.52418578\nStep    200: eval  CrossEntropyLoss |  0.47771186\nStep    200: eval          Accuracy |  0.75000000\n\nStep    210: Ran 10 train steps in 159.23 secs\nStep    210: train CrossEntropyLoss |  0.50326890\nStep    210: eval  CrossEntropyLoss |  0.53428078\nStep    210: eval          Accuracy |  0.75000000\n\nStep    220: Ran 10 train steps in 166.84 secs\nStep    220: train CrossEntropyLoss |  0.55388230\nStep    220: eval  CrossEntropyLoss |  0.37349233\nStep    220: eval          Accuracy |  0.87500000\n\nStep    230: Ran 10 train steps in 142.49 secs\nStep    230: train CrossEntropyLoss |  0.41967654\nStep    230: eval  CrossEntropyLoss |  0.78132755\nStep    230: eval          Accuracy |  0.68750000\n\nStep    240: Ran 10 train steps in 141.32 secs\nStep    240: train CrossEntropyLoss |  0.41357833\nStep    240: eval  CrossEntropyLoss |  0.42281815\nStep    240: eval          Accuracy |  0.87500000\n\nStep    250: Ran 10 train steps in 139.79 secs\nStep    250: train CrossEntropyLoss |  0.42972288\nStep    250: eval  CrossEntropyLoss |  0.33060262\nStep    250: eval          Accuracy |  0.87500000\n\nStep    260: Ran 10 train steps in 138.32 secs\nStep    260: train CrossEntropyLoss |  0.42513147\nStep    260: eval  CrossEntropyLoss |  0.32280594\nStep    260: eval          Accuracy |  0.87500000\n\nStep    270: Ran 10 train steps in 137.82 secs\nStep    270: train CrossEntropyLoss |  0.52831471\nStep    270: eval  CrossEntropyLoss |  0.55629498\nStep    270: eval          Accuracy |  0.81250000\n\nStep    280: Ran 10 train steps in 136.63 secs\nStep    280: train CrossEntropyLoss |  0.38021794\nStep    280: eval  CrossEntropyLoss |  0.25516164\nStep    280: eval          Accuracy |  0.87500000\n\nStep    290: Ran 10 train steps in 138.75 secs\nStep    290: train CrossEntropyLoss |  0.36841637\nStep    290: eval  CrossEntropyLoss |  0.51705146\nStep    290: eval          Accuracy |  0.81250000\n\nStep    300: Ran 10 train steps in 141.20 secs\nStep    300: train CrossEntropyLoss |  0.41775975\nStep    300: eval  CrossEntropyLoss |  0.42897648\nStep    300: eval          Accuracy |  0.75000000\n\nStep    310: Ran 10 train steps in 137.75 secs\nStep    310: train CrossEntropyLoss |  0.57674128\nStep    310: eval  CrossEntropyLoss |  0.57324839\nStep    310: eval          Accuracy |  0.75000000\n\nStep    320: Ran 10 train steps in 138.36 secs\nStep    320: train CrossEntropyLoss |  0.39956793\nStep    320: eval  CrossEntropyLoss |  0.60206795\nStep    320: eval          Accuracy |  0.81250000\n\nStep    330: Ran 10 train steps in 141.30 secs\nStep    330: train CrossEntropyLoss |  0.41691390\nStep    330: eval  CrossEntropyLoss |  0.40016580\nStep    330: eval          Accuracy |  0.81250000\n\nStep    340: Ran 10 train steps in 142.10 secs\nStep    340: train CrossEntropyLoss |  0.27749163\nStep    340: eval  CrossEntropyLoss |  0.40680838\nStep    340: eval          Accuracy |  0.81250000\n\nStep    350: Ran 10 train steps in 143.84 secs\nStep    350: train CrossEntropyLoss |  0.49674684\nStep    350: eval  CrossEntropyLoss |  0.66092521\nStep    350: eval          Accuracy |  0.75000000\n\nStep    360: Ran 10 train steps in 138.20 secs\nStep    360: train CrossEntropyLoss |  0.57859111\nStep    360: eval  CrossEntropyLoss |  0.44950938\nStep    360: eval          Accuracy |  0.81250000\n\nStep    370: Ran 10 train steps in 137.13 secs\nStep    370: train CrossEntropyLoss |  0.35311845\nStep    370: eval  CrossEntropyLoss |  0.70435977\nStep    370: eval          Accuracy |  0.75000000\n\nStep    380: Ran 10 train steps in 139.69 secs\nStep    380: train CrossEntropyLoss |  0.29908043\nStep    380: eval  CrossEntropyLoss |  0.09821636\nStep    380: eval          Accuracy |  1.00000000\n\nStep    390: Ran 10 train steps in 137.51 secs\nStep    390: train CrossEntropyLoss |  0.32866904\nStep    390: eval  CrossEntropyLoss |  0.25326717\nStep    390: eval          Accuracy |  0.93750000\n\nStep    400: Ran 10 train steps in 141.20 secs\nStep    400: train CrossEntropyLoss |  0.41468304\nStep    400: eval  CrossEntropyLoss |  0.27574378\nStep    400: eval          Accuracy |  0.87500000\n\nStep    410: Ran 10 train steps in 136.29 secs\nStep    410: train CrossEntropyLoss |  0.31047970\nStep    410: eval  CrossEntropyLoss |  0.35586554\nStep    410: eval          Accuracy |  0.81250000\n\nStep    420: Ran 10 train steps in 138.09 secs\nStep    420: train CrossEntropyLoss |  0.26427266\nStep    420: eval  CrossEntropyLoss |  0.80101740\nStep    420: eval          Accuracy |  0.50000000\n\nStep    430: Ran 10 train steps in 137.18 secs\nStep    430: train CrossEntropyLoss |  0.33543786\nStep    430: eval  CrossEntropyLoss |  0.41998935\nStep    430: eval          Accuracy |  0.87500000\n\nStep    440: Ran 10 train steps in 136.80 secs\nStep    440: train CrossEntropyLoss |  0.30534899\nStep    440: eval  CrossEntropyLoss |  0.64952862\nStep    440: eval          Accuracy |  0.68750000\n\nStep    450: Ran 10 train steps in 137.50 secs\nStep    450: train CrossEntropyLoss |  0.39875236\nStep    450: eval  CrossEntropyLoss |  0.36040884\nStep    450: eval          Accuracy |  0.81250000\n\nStep    460: Ran 10 train steps in 139.85 secs\nStep    460: train CrossEntropyLoss |  0.36516705\nStep    460: eval  CrossEntropyLoss |  0.53565013\nStep    460: eval          Accuracy |  0.87500000\n\nStep    470: Ran 10 train steps in 141.80 secs\nStep    470: train CrossEntropyLoss |  0.32150912\nStep    470: eval  CrossEntropyLoss |  0.22056799\nStep    470: eval          Accuracy |  0.93750000\n\nStep    480: Ran 10 train steps in 136.40 secs\nStep    480: train CrossEntropyLoss |  0.43209738\nStep    480: eval  CrossEntropyLoss |  0.30534989\nStep    480: eval          Accuracy |  0.81250000\n\nStep    490: Ran 10 train steps in 138.02 secs\nStep    490: train CrossEntropyLoss |  0.32457778\nStep    490: eval  CrossEntropyLoss |  0.64571166\nStep    490: eval          Accuracy |  0.62500000\n\nStep    500: Ran 10 train steps in 143.55 secs\nStep    500: train CrossEntropyLoss |  0.35971847\nStep    500: eval  CrossEntropyLoss |  0.25983956\nStep    500: eval          Accuracy |  0.87500000\n\nStep    510: Ran 10 train steps in 138.60 secs\nStep    510: train CrossEntropyLoss |  0.36111718\nStep    510: eval  CrossEntropyLoss |  0.65420485\nStep    510: eval          Accuracy |  0.56250000\n\nStep    520: Ran 10 train steps in 136.35 secs\nStep    520: train CrossEntropyLoss |  0.30737436\nStep    520: eval  CrossEntropyLoss |  0.25448260\nStep    520: eval          Accuracy |  0.93750000\n\nStep    530: Ran 10 train steps in 138.90 secs\nStep    530: train CrossEntropyLoss |  0.32453480\nStep    530: eval  CrossEntropyLoss |  0.34766841\nStep    530: eval          Accuracy |  0.81250000\n\nStep    540: Ran 10 train steps in 136.43 secs\nStep    540: train CrossEntropyLoss |  0.23810346\nStep    540: eval  CrossEntropyLoss |  0.14565909\nStep    540: eval          Accuracy |  0.93750000\n\nStep    550: Ran 10 train steps in 137.32 secs\nStep    550: train CrossEntropyLoss |  0.29092824\nStep    550: eval  CrossEntropyLoss |  0.36414942\nStep    550: eval          Accuracy |  0.87500000\n\nStep    560: Ran 10 train steps in 137.67 secs\nStep    560: train CrossEntropyLoss |  0.35140425\nStep    560: eval  CrossEntropyLoss |  0.48509538\nStep    560: eval          Accuracy |  0.68750000\n\nStep    570: Ran 10 train steps in 136.27 secs\nStep    570: train CrossEntropyLoss |  0.33753946\nStep    570: eval  CrossEntropyLoss |  0.38388184\nStep    570: eval          Accuracy |  0.87500000\n\nStep    580: Ran 10 train steps in 137.72 secs\nStep    580: train CrossEntropyLoss |  0.29096517\nStep    580: eval  CrossEntropyLoss |  0.61163855\nStep    580: eval          Accuracy |  0.81250000\n\nStep    590: Ran 10 train steps in 135.17 secs\nStep    590: train CrossEntropyLoss |  0.28786072\nStep    590: eval  CrossEntropyLoss |  0.44452232\nStep    590: eval          Accuracy |  0.75000000\n\nStep    600: Ran 10 train steps in 139.28 secs\nStep    600: train CrossEntropyLoss |  0.32629800\nStep    600: eval  CrossEntropyLoss |  0.36045074\nStep    600: eval          Accuracy |  0.81250000\n\nStep    610: Ran 10 train steps in 139.10 secs\nStep    610: train CrossEntropyLoss |  0.32893795\nStep    610: eval  CrossEntropyLoss |  0.30440155\nStep    610: eval          Accuracy |  0.87500000\n\nStep    620: Ran 10 train steps in 138.68 secs\nStep    620: train CrossEntropyLoss |  0.38909715\nStep    620: eval  CrossEntropyLoss |  0.59170491\nStep    620: eval          Accuracy |  0.68750000\n\nStep    630: Ran 10 train steps in 137.69 secs\nStep    630: train CrossEntropyLoss |  0.41549248\nStep    630: eval  CrossEntropyLoss |  0.39469272\nStep    630: eval          Accuracy |  0.81250000\n\nStep    640: Ran 10 train steps in 140.34 secs\nStep    640: train CrossEntropyLoss |  0.31689200\nStep    640: eval  CrossEntropyLoss |  0.21891432\nStep    640: eval          Accuracy |  0.87500000\n\nStep    650: Ran 10 train steps in 133.96 secs\nStep    650: train CrossEntropyLoss |  0.31481901\nStep    650: eval  CrossEntropyLoss |  0.77630889\nStep    650: eval          Accuracy |  0.68750000\n\nStep    660: Ran 10 train steps in 138.63 secs\nStep    660: train CrossEntropyLoss |  0.33964843\nStep    660: eval  CrossEntropyLoss |  0.54861486\nStep    660: eval          Accuracy |  0.81250000\n\nStep    670: Ran 10 train steps in 136.12 secs\nStep    670: train CrossEntropyLoss |  0.34154534\nStep    670: eval  CrossEntropyLoss |  0.20657007\nStep    670: eval          Accuracy |  0.87500000\n\nStep    680: Ran 10 train steps in 142.62 secs\nStep    680: train CrossEntropyLoss |  0.23044038\nStep    680: eval  CrossEntropyLoss |  0.19371712\nStep    680: eval          Accuracy |  0.87500000\n\nStep    690: Ran 10 train steps in 139.02 secs\nStep    690: train CrossEntropyLoss |  0.30941653\nStep    690: eval  CrossEntropyLoss |  0.63304996\nStep    690: eval          Accuracy |  0.75000000\n\nStep    700: Ran 10 train steps in 142.14 secs\nStep    700: train CrossEntropyLoss |  0.43473691\nStep    700: eval  CrossEntropyLoss |  0.22951123\nStep    700: eval          Accuracy |  0.87500000\n\nStep    710: Ran 10 train steps in 136.17 secs\nStep    710: train CrossEntropyLoss |  0.36294103\nStep    710: eval  CrossEntropyLoss |  0.44011718\nStep    710: eval          Accuracy |  0.81250000\n\nStep    720: Ran 10 train steps in 138.31 secs\nStep    720: train CrossEntropyLoss |  0.26043552\nStep    720: eval  CrossEntropyLoss |  0.32396805\nStep    720: eval          Accuracy |  0.87500000\n\nStep    730: Ran 10 train steps in 140.89 secs\nStep    730: train CrossEntropyLoss |  0.29769063\nStep    730: eval  CrossEntropyLoss |  0.35829103\nStep    730: eval          Accuracy |  0.87500000\n\nStep    740: Ran 10 train steps in 136.26 secs\nStep    740: train CrossEntropyLoss |  0.32549936\nStep    740: eval  CrossEntropyLoss |  0.40364727\nStep    740: eval          Accuracy |  0.87500000\n\nStep    750: Ran 10 train steps in 138.88 secs\nStep    750: train CrossEntropyLoss |  0.28288040\nStep    750: eval  CrossEntropyLoss |  0.28596497\nStep    750: eval          Accuracy |  0.81250000\n\nStep    760: Ran 10 train steps in 136.28 secs\nStep    760: train CrossEntropyLoss |  0.29867586\nStep    760: eval  CrossEntropyLoss |  0.29929778\nStep    760: eval          Accuracy |  0.87500000\n\nStep    770: Ran 10 train steps in 139.31 secs\nStep    770: train CrossEntropyLoss |  0.37390631\nStep    770: eval  CrossEntropyLoss |  0.34522048\nStep    770: eval          Accuracy |  0.81250000\n\nStep    780: Ran 10 train steps in 137.98 secs\nStep    780: train CrossEntropyLoss |  0.23807883\nStep    780: eval  CrossEntropyLoss |  0.26420116\nStep    780: eval          Accuracy |  0.87500000\n\nStep    790: Ran 10 train steps in 137.62 secs\nStep    790: train CrossEntropyLoss |  0.36344522\nStep    790: eval  CrossEntropyLoss |  0.51577538\nStep    790: eval          Accuracy |  0.75000000\n\nStep    800: Ran 10 train steps in 137.45 secs\nStep    800: train CrossEntropyLoss |  0.32706428\nStep    800: eval  CrossEntropyLoss |  0.31912795\nStep    800: eval          Accuracy |  0.87500000\n\nStep    810: Ran 10 train steps in 138.81 secs\nStep    810: train CrossEntropyLoss |  0.25640488\nStep    810: eval  CrossEntropyLoss |  0.24663949\nStep    810: eval          Accuracy |  0.93750000\n\nStep    820: Ran 10 train steps in 139.03 secs\nStep    820: train CrossEntropyLoss |  0.30187640\nStep    820: eval  CrossEntropyLoss |  0.70219219\nStep    820: eval          Accuracy |  0.62500000\n\nStep    830: Ran 10 train steps in 138.56 secs\nStep    830: train CrossEntropyLoss |  0.24405348\nStep    830: eval  CrossEntropyLoss |  0.21909121\nStep    830: eval          Accuracy |  0.93750000\n\nStep    840: Ran 10 train steps in 137.69 secs\nStep    840: train CrossEntropyLoss |  0.24172655\nStep    840: eval  CrossEntropyLoss |  0.31466490\nStep    840: eval          Accuracy |  0.75000000\n\nStep    850: Ran 10 train steps in 136.02 secs\nStep    850: train CrossEntropyLoss |  0.29800558\nStep    850: eval  CrossEntropyLoss |  0.68874478\nStep    850: eval          Accuracy |  0.62500000\n\nStep    860: Ran 10 train steps in 138.04 secs\nStep    860: train CrossEntropyLoss |  0.25477284\nStep    860: eval  CrossEntropyLoss |  0.28123948\nStep    860: eval          Accuracy |  0.87500000\n\nStep    870: Ran 10 train steps in 138.76 secs\nStep    870: train CrossEntropyLoss |  0.29686192\nStep    870: eval  CrossEntropyLoss |  0.37342680\nStep    870: eval          Accuracy |  0.75000000\n\nStep    880: Ran 10 train steps in 136.99 secs\nStep    880: train CrossEntropyLoss |  0.27514809\nStep    880: eval  CrossEntropyLoss |  0.66405475\nStep    880: eval          Accuracy |  0.81250000\n\nStep    890: Ran 10 train steps in 135.31 secs\nStep    890: train CrossEntropyLoss |  0.22881842\nStep    890: eval  CrossEntropyLoss |  0.16644877\nStep    890: eval          Accuracy |  0.93750000\n\nStep    900: Ran 10 train steps in 139.65 secs\nStep    900: train CrossEntropyLoss |  0.24959481\nStep    900: eval  CrossEntropyLoss |  0.29835165\nStep    900: eval          Accuracy |  0.87500000\n\nStep    910: Ran 10 train steps in 137.44 secs\nStep    910: train CrossEntropyLoss |  0.32166880\nStep    910: eval  CrossEntropyLoss |  0.20436230\nStep    910: eval          Accuracy |  0.87500000\n\nStep    920: Ran 10 train steps in 138.72 secs\nStep    920: train CrossEntropyLoss |  0.26416394\nStep    920: eval  CrossEntropyLoss |  0.64696896\nStep    920: eval          Accuracy |  0.81250000\n\nStep    930: Ran 10 train steps in 136.11 secs\nStep    930: train CrossEntropyLoss |  0.31040630\nStep    930: eval  CrossEntropyLoss |  0.16369335\nStep    930: eval          Accuracy |  0.87500000\n\nStep    940: Ran 10 train steps in 137.09 secs\nStep    940: train CrossEntropyLoss |  0.37380749\nStep    940: eval  CrossEntropyLoss |  0.50875771\nStep    940: eval          Accuracy |  0.75000000\n\nStep    950: Ran 10 train steps in 138.05 secs\nStep    950: train CrossEntropyLoss |  0.29238093\nStep    950: eval  CrossEntropyLoss |  0.54448801\nStep    950: eval          Accuracy |  0.68750000\n\nStep    960: Ran 10 train steps in 139.06 secs\nStep    960: train CrossEntropyLoss |  0.37032086\nStep    960: eval  CrossEntropyLoss |  0.10701004\nStep    960: eval          Accuracy |  1.00000000\n\nStep    970: Ran 10 train steps in 137.09 secs\nStep    970: train CrossEntropyLoss |  0.28297603\nStep    970: eval  CrossEntropyLoss |  0.70442963\nStep    970: eval          Accuracy |  0.75000000\n\nStep    980: Ran 10 train steps in 137.67 secs\nStep    980: train CrossEntropyLoss |  0.24297890\nStep    980: eval  CrossEntropyLoss |  0.34878114\nStep    980: eval          Accuracy |  0.93750000\n\nStep    990: Ran 10 train steps in 141.24 secs\nStep    990: train CrossEntropyLoss |  0.37200943\nStep    990: eval  CrossEntropyLoss |  0.87685275\nStep    990: eval          Accuracy |  0.62500000\n\nStep   1000: Ran 10 train steps in 141.35 secs\nStep   1000: train CrossEntropyLoss |  0.22355890\nStep   1000: eval  CrossEntropyLoss |  0.26179990\nStep   1000: eval          Accuracy |  0.93750000\n"
    }
   ],
   "source": [
    "'''\n",
    "OS : macOS Catalina\n",
    "Processor : i5 @ 2.30GHz\n",
    "RAM : 8GB @ 2133MHz\n",
    "Storage : SSD 256GB\n",
    "'''\n",
    "start_time = time.time()\n",
    "training_loop = NNM.train_model(model, train_task, eval_task, 1000, output_dir_expand)\n",
    "finish_time = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Train model process elapsed time: 3:57:59.788814\n"
    }
   ],
   "source": [
    "print('Train model process elapsed time: {}'.format(timedelta(seconds=finish_time-start_time)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Model's prediction accuracy on a single batch is : 78.125%\nWeighted number of correct prediction 50.0, weighted number of total observations predicted 64\n"
    }
   ],
   "source": [
    "# EVALUATE THE MODEL\n",
    "eval_val_gen = NND.val_generator(x_test_pos, x_test_neg, vocab, 64, False)\n",
    "eval_batch = next(eval_val_gen)\n",
    "eval_inp, eval_targ, eval_ew = eval_batch\n",
    "\n",
    "eval_pred = training_loop.eval_model(eval_inp)\n",
    "eval_acc, eval_num_correct, eval_num_pred = NNM.compute_accuracy(eval_pred, eval_targ, eval_ew)\n",
    "\n",
    "print(f'Model\\'s prediction accuracy on a single batch is : {100*eval_acc}%')\n",
    "print(f'Weighted number of correct prediction {eval_num_correct}, weighted number of total observations predicted {eval_num_pred}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "The accuracy of the model on the validation set is 0.8537\n"
    }
   ],
   "source": [
    "# TESTING THE ACCURACY OF MODEL\n",
    "mdl = training_loop.eval_model\n",
    "accuracy = NNM.test_model(NND.test_generator(x_test_pos, x_test_neg, vocab, 16, False), mdl)\n",
    "\n",
    "print(f'The accuracy of the model on the validation set is {accuracy:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "precision    recall  f1-score   support\n\n           0       0.85      0.87      0.86      1527\n           1       0.85      0.82      0.84      1312\n\n    accuracy                           0.85      2839\n   macro avg       0.85      0.85      0.85      2839\nweighted avg       0.85      0.85      0.85      2839\n\n"
    }
   ],
   "source": [
    "classfctnReport = NNM.confusionMatrix(x_test, y_test, mdl, alay_lang, vocab)\n",
    "print(classfctnReport)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "The sentiment of the tweet \"emang dasar bangsat aja lo nya\" is negative\n"
    }
   ],
   "source": [
    "# TEST PREDICT USING MANUAL INPUT 1\n",
    "sentence = \"emang dasar bangsat aja lo nya\"\n",
    "user_pred, user_sentiment = NNM.predictUserInput(sentence, mdl, alay_lang, vocab)\n",
    "print(f'The sentiment of the tweet \"{sentence}\" is {user_sentiment}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "The sentiment of the tweet \"kekuatan cinta tidak akan terkalahkan\" is positive\n"
    }
   ],
   "source": [
    "# TEST PREDICT USING MANUAL INPUT 2\n",
    "sentence = \"kekuatan cinta tidak akan terkalahkan\"\n",
    "user_pred, user_sentiment = NNM.predictUserInput(sentence, mdl, alay_lang, vocab)\n",
    "print(f'The sentiment of the tweet \"{sentence}\" is {user_sentiment}')"
   ]
  }
 ]
}